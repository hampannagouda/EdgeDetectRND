EdgeDetectRND â€” Real-Time Edge Detection Framework (Android Â· OpenCV Â· OpenGL ES Â· Web)

A high-performance real-time computer vision pipeline combining Android Camera2, C++/JNI, OpenCV, and OpenGL ES 2.0.
Includes a lightweight TypeScript web viewer to demonstrate multi-platform rendering of processed frames.

This project was built as part of an R&D Engineering Assignment, showcasing expertise in low-level rendering, native performance optimization, and cross-platform visualization.

âœ¨ Why This Project Stands Out

âœ” Zero-copy camera pipeline using SurfaceTexture
âœ” Native NV21 â†’ RGBA conversion with OpenCV
âœ” Real-time Canny Edge Detection (OpenCV C++)
âœ” GPU-accelerated rendering through OpenGL ES 2.0
âœ” JNI bridging with clean architecture
âœ” Raw â‡„ Edge mode toggle
âœ” Native FPS tracking
âœ” TypeScript web viewer that renders processed frames
âœ” Production-grade structure, ready for future enhancements

ğŸš€ Live Architecture Overview
Android Camera2 (YUV_420_888)
        â†“
ImageReader â†’ Java (CameraRenderer)
        â†“ JNI Bridge (byte* â†’ Mat)
C++ Native Layer (OpenCV)
        â€¢ NV21 â†’ RGBA
        â€¢ Canny Edge Detection
        â€¢ FPS Calculation
        â†“
OpenGL ES 2.0 Renderer
        â†“
TextureView â†’ Live Display


Web Viewer Flow:

static sample / base64 frame
        â†“
TypeScript (viewer.ts)
        â†“
Canvas / <img> rendering

ğŸ“¸ Preview

(Add your screenshot or GIF here to showcase the output)

Example placeholder:

screenshots/demo.png

ğŸ§© Project Structure
EdgeDetectRND/
 â”œâ”€â”€ app/                     # Android Java (Camera, GL, UI)
 â”œâ”€â”€ jni/
 â”‚    â”œâ”€â”€ native-lib.cpp      # C++ | OpenCV | OpenGL ES pipeline
 â”‚    â””â”€â”€ CMakeLists.txt
 â”œâ”€â”€ web/
 â”‚    â”œâ”€â”€ src/                # TypeScript viewer
 â”‚    â”œâ”€â”€ dist/
 â”‚    â””â”€â”€ package.json        # Web build scripts
 â”œâ”€â”€ screenshots/
 â”œâ”€â”€ README.md
 â””â”€â”€ .gitignore

ğŸ› ï¸ Tech Stack
Android

Camera2 API

TextureView + SurfaceTexture

OpenGL ES 2.0

JNI + Native C++

OpenCV 4.x

Web

TypeScript

ES Modules

Lightweight static viewer

Canvas / DOM rendering

âš™ï¸ Setup Instructions
1ï¸âƒ£ Prerequisites

Android Studio Hedgehog / Iguana or newer

NDK r25c+

CMake 3.22+

OpenCV Android SDK 4.8.0+

Node.js LTS (for web viewer)

2ï¸âƒ£ Install OpenCV

Download OpenCV Android SDK:
ğŸ”— https://opencv.org/releases/

Extract and place:

jni/opencv/OpenCV-android-sdk/

3ï¸âƒ£ Build & Run Android App

Open project in Android Studio

Sync Gradle

Connect a device (API 24+)

Run â†’ Grant camera permission

You should now see a real-time processed camera feed with an Edge / Raw toggle and FPS counter.

4ï¸âƒ£ Web Viewer Setup
cd web
npm install
npm run build
npm run start


Then open:

http://localhost:3000


This loads a dummy processed frame (static image), proving cross-platform renderability.

ğŸ§  Deep-Dive: Native Processing Flow
1. Frame Acquisition

Camera frames arrive as YUV_420_888.
We convert to NV21 respecting row + pixel stride.

2. JNI Transfer

NV21 byte array â†’ C++ via processFrame().

3. OpenCV Processing

cvtColor(NV21 â†’ RGBA)

optional Canny(gray) edge mask

merge back to RGBA for GL

4. OpenGL ES Texture Update

Updated RGBA buffer is pushed via:

glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, width, height, GL_RGBA, GL_UNSIGNED_BYTE, rgbaMat.data);


Rendering handled in GLTextureRenderer.

5. FPS Callback

C++ computes FPS and invokes Java callback via JNI global reference.

ğŸ”® Future Enhancements (Optional)

WebSocket live streaming to browser

PBO-based async texture upload

GPU-based Canny (compute shaders)

Flutter/WebAssembly viewer

AI-powered real-time segmentation


ğŸ¤ Contributions

PRs, suggestions, and improvements are welcome!

ğŸ Final Note

This repository demonstrates mastery of:

Android low-level camera APIs

Native C++ development

OpenCV image processing

GPU rendering

Cross-platform architecture

Clean engineering practices

Use this as a strong showcase of your technical depth.

Thank You!.